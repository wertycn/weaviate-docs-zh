---
authors:
- etienne
date: 2022-08-15
description: Go 1.19 introduced GOMEMLIMIT, which completely changes how you can manage
  memory limits in Go. Learn how it helps Weaviate be more reliable.
image: ./img/hero.jpg
slug: gomemlimit-a-game-changer-for-high-memory-applications
tags:
- engineering
title: GOMEMLIMIT is a game changer for high-memory applications
---

![GOMEMLIMIT Gopher](./img/intro.jpg)

<!-- 截断 -->

## 简介
内存耗尽从来都不是一件有趣的事情，但是当您已经采取了一些预防措施并计算了确切的内存需求时，却非常令人沮丧。"我的应用程序需要4GB的内存。在我的6GB机器上怎么可能内存耗尽！？"事实证明，在像Golang这样的垃圾回收（"GC"）语言中，这是一个真正的可能性。重点在于"是"这个词，因为Go 1.19改变了一切：新的`GOMEMLIMIT`功能可以帮助您提高与GC相关的性能，并避免GC相关的内存耗尽（"OOM"）情况。

在本文中，我将邀请您进行一次旅程。我们将涵盖以下内容：
* Go语言中的内存分配工作原理。
* 垃圾回收器何时运行以及其影响。
* 在Go 1.19之前为什么很容易耗尽内存。
* GOMEMLIMIT是什么以及为什么它可以防止过早的OOM（内存耗尽）。
* 先进行一个没有GOMEMLIMIT的实验，然后再进行一个有GOMEMLIMIT的实验。

## 什么是垃圾回收语言？
在垃圾回收的语言中，比如Go、C#或Java，程序员在使用完对象后不需要手动释放内存。垃圾回收器会定期运行，收集不再需要的内存，并确保可以重新分配。使用垃圾回收的语言是开发复杂性和执行时间之间的权衡。一些CPU时间必须在运行时用于运行垃圾回收周期。

Go的垃圾回收器高度并发且非常高效，这使得Go成为两个世界之间的一个很好的折中方案。它的语法简单直观，内存相关的错误（如内存泄漏）的潜在风险很低。与此同时，Go程序在GC相关活动上所花费的CPU时间往往不到1%。考虑到平均程序对执行效率的优化程度很低，只花费1%的执行时间来进行交换是一笔相当划算的交易。毕竟，谁想要在使用内存后还要担心释放它呢？

然而，正如接下来的几段文字所示，还存在一些注意事项（以及一个名为GOMEMLIMIT的绝佳新解决方案）。如果不小心的话，即使不应该发生，也可能遇到OOM（内存溢出）的情况。但在深入讨论之前，我们需要讨论一下栈和堆分配以及为什么某些东西最终会出现在堆上。

## 栈 vs. 堆
简而言之，有两种分配内存的方式：栈上分配和堆上分配。栈上分配的生命周期较短，通常非常廉价。栈上分配不需要垃圾回收，因为函数的结束也意味着变量的生命周期结束。另一方面，堆上分配的生命周期较长，成本相对较高。在堆上分配时，运行时必须找到一个连续的内存块来存放新的变量。此外，当变量不再使用时，还必须进行垃圾回收。这两个操作的代价比栈上分配高出几个数量级。

让我们来看两个简单的例子。第一个例子是一个函数，它接受两个数字，对它们进行平方运算，并返回平方和：

```
func SumSquares(a, b float64) float64 {
  aSquared := a * a
  bSquared := b * b
  return aSquared + bSquared
}
```

毋庸置疑，这个函数比必需的冗长。这是故意为了展示许多可以存在于堆栈上的变量。有四个变量（a、b、aSquared和bSquared）。它们中没有一个在此函数块之外“逃逸”。因此，Go运行时可以将它们分配到堆栈上。换句话说，这些分配是廉价的。垃圾收集器永远不会知道它们的存在。

现在，让我们来看一些逃逸到堆上的东西。一个示例应用程序是缓存。缓存是长期存在的，并且需要保持存在，即使与缓存交互的特定函数已经返回。例如：

```
var cache = map[string]string{}

func Put(key, value string) {
  cache[key] = value
}
```

在上面的示例中，cache变量是在堆上分配的。它在Put被调用之前存在，并且在Put返回之后仍然存在。这绝不是为什么某些东西逃逸到堆上的唯一标准，但对于我们理解与GC相关的OOM情况来说，这应该足够了。

### 当事物意外逃逸到堆上时
之前的示例展示了两种不同的情况：短暂的分配在栈上结束，长期的分配在堆上结束。实际上，并不总是这么简单。有时候你会遇到无意中的堆分配。你分配了一个你认为应该是短暂的变量，然而它却在堆上分配了。为什么以及如何发生这种情况是一个单独的博文主题。这是关于Go内存管理的一个我最喜欢的话题，我很乐意写这篇博文。请告诉我。对于这个问题，只需要理解有时候堆分配会发生，即使我们认为它们不应该发生。这是很重要的，因为这些分配会给GC带来压力，而GC对于意外的OOM情况是必需的。


## 即使有足够的内存可用，为什么会出现OOM（内存不足）的情况？
在前面的章节中，我们概述了大多数应用程序具有短期和长期的内存。长期内存是您可以预先估计或在运行时进行控制的内容。例如，如果您想将上面的简单缓存示例扩展为完整的缓存应用程序，您很可能会实现某种限制。当缓存满时，缓存将停止接受新值或丢弃旧值。您可以确保缓存的大小永远不会超过4GB。那么在您的6GB机器上应该是安全的，对吗？答案是可能。但是，当内存不足的风险存在时，“可能”是不够的。

要理解为什么在这种情况下可能会发生OOM，我们需要了解垃圾回收器何时运行。让我们先思考一个从不运行垃圾回收器的示例。我们知道我们有4GB的活动内存，并且通过使用应用程序，我们会不断地添加一些短暂的堆分配。我们不希望它们在长期内存在，但由于当前没有运行的GC周期，它们也永远不会被释放。最终，当有意和无意的活动堆超过6GB时，我们将遇到OOM错误。

![OOM Kill over 6GB](./img/oom-kill.png)

现在让我们看一下另一个极端情况。假设垃圾收集器非常频繁地运行。每当我们的堆达到4.1GB时，它会运行并删除100MB的临时分配。现在出现OOM的情况是不太可能的，但我们已经远远超出了成本目标。我们的应用程序现在可能会花费25-30%（或更多）的时间在垃圾收集上。换句话说，它不再高效：

![Intense garpace collector](./img/intense-garbage-collector.png)

因此，我们希望兼顾两全；尽可能接近我们的限制，但永远不要超过它。这样，我们可以推迟垃圾回收循环，直到它们真正必要。这使得我们的程序快速运行。但与此同时，我们可以确保我们永远不会越过阈值。这使得我们的程序免受OOM（内存不足）杀死的影响。换句话说，我们理想的情况应该是像下面这样的：

![延迟垃圾回收器](./img/delayed-garbage-collector.png)

### 以前的垃圾回收目标始终是相对的。
从上面的三个图表中可以看出，这是非常明显的。我们想要充分利用我们拥有的内存而不超过它。然而，在Go 1.19之前，您只有一个可以调整的选项：GOGC环境变量。该变量接受相对于当前活动堆大小的目标值。GOGC的默认值为100，意味着堆应该增加一倍（即增长100％）才能再次运行垃圾回收。

这对于具有小型永久性活动堆的应用程序非常有效。例如，如果您的常量堆只有100MB，而您有6GB可用空间，您可以多次增加堆目标，而不会有任何危险。如果应用程序的负载增加并且临时分配增加，您的动态目标将是200MB、400MB、800MB、1600MB和3200MB。您的负载必须增加六次才能超过6GB的标记。换句话说，内存耗尽的可能性非常小。

但现在，让我们回想一下我们的缓存应用程序，在一台6GB的机器上具有一个永久的4GB活动堆。即使是堆的第一次加倍也是非常有问题的，因为新的目标（8GB）已经超过了机器上的物理内存。

在过去，我们对此无能为力。记住，GOGC是我们唯一能调整的参数。因此，我们可能会选择一个值，例如GOGC=25。这意味着堆可以增长25%，以触发垃圾回收。我们的新目标现在是5GB；除非负载发生 drastical 改变，否则我们应该能够安全地避免再次发生OOM。

但是这个场景只考虑了一个时间点的快照。我们假设我们总是以4GB的活动堆开始。这是一个过于简化的假设，在现实中不一定总是成立。如果缓存中的项目较少，活动堆只有100MB，那么我们的堆目标就只有125MB。换句话说，我们将会出现频繁的GC循环。它们会占用大量的CPU时间。结果，用户界面的延迟以及整体吞吐量都会受到影响。

### 当内存很多时，减少侵占性；当内存很少时，提高侵占性。
我们想要的是在有大量可用内存时，垃圾回收器（GC）不会非常频繁地运行（即很少运行），但是当内存稀缺时，GC应该变得非常积极。在过去，这只能通过一种变通方法实现。所谓的GC ballast方法是Twitch工程师们推广的一种技术。在应用程序启动时，您会分配一个ballast，例如一个占用大量内存的字节数组。由于堆现在很大，您可以让GOGC非常积极。保持我们上面的数字不变：如果您分配了一个4GB的ballast并设置GOGC=25，GC将不会在分配了5GB的内存之前运行。

你可能会想这个练习是否违背了初衷？是的，这样做会推迟第一次垃圾回收周期，但是我们现在在堆上有了4GB的无用内存分配，这不是浪费吗？答案是“不完全是”，因为这些负载只占用虚拟内存。这个概念在Twitch的文章中有很好的解释。

## GOMEMLIMIT - 不再需要变通方法
虽然我喜欢使用虚拟内存作为压舱物的创新思路，但这仍然是一个解决方法 - 首先你应该永远不需要这样做。而且，通过Go 1.19，我们终于有了一个更好的解决方案。GOMEMLIMIT允许指定一个软内存限制。它不取代GOGC，而是与之配合使用。您可以为内存始终可用的场景设置GOGC。同时，您可以相信当内存稀缺时，GOMEMLIMIT会自动使GC更加积极。换句话说，GOMEMLIMIT正是我们之前提到的缺失的关键部分。

如果当前堆的使用量较低（例如，100MB），我们可以延迟下一次GC循环，直到堆的使用量增加到两倍（200MB）。但是，如果堆的使用量接近我们设定的限制（例如，4GB），为了防止OOM，GC会更频繁地运行。

### 为什么使用软限制？软限制和硬限制有什么区别？
Go的作者明确将GOMEMLIMIT标记为“软”限制。这意味着Go运行时不能保证内存使用量超过限制。相反，它将其作为目标使用。目标是在无法解决的情况下快速失败：假设我们将限制设置为比活动堆稍大几千字节的值。垃圾回收（GC）将不得不持续运行。我们将处于常规执行和GC执行竞争相同资源的情况下。应用程序将停滞。由于没有其他方法可以解决这个问题，除了使用更多的内存，因此Go运行时更喜欢OOM（内存耗尽）的情况。所有可用的内存都已经被使用，不再能够释放。这是一种失败的情况，快速失败是首选。这使得限制成为软限制。仍然可以跨越限制-从内核中调用OOM kill-但仅当活动堆完全耗尽，并且运行时无法采取其他任何措施时。

## 添加 GOMEMLIMIT 到 Weaviate - 之前和之后
[Weaviate](/developers/weaviate) 是我们正在构建的向量数据库。作为一个数据库提供者，我们既关注内存溢出的安全性，也关注性能。使用默认设置，Weaviate将创建一个内存中的索引，用于高效的基于向量的检索。换句话说，用户导入的数据越多，堆内存就会增长得越多。这使得最终我们将得到的实时堆内存大小很难预测。换句话说，Weaviate - 像其他内存密集型的Go应用程序一样 - 是GOMEMLIMIT的理想候选者。它还支持[兼容Prometheus的监控](/developers/weaviate/configuration/monitoring)，因此很容易可视化堆内存的使用情况。

对于这个实验，我们将使用使用Go 1.19编译的最新Weaviate版本。我们将在Docker中运行它，这样可以非常容易地限制可用内存。根据我们即将导入的内容，我们预计实际使用的堆内存应该约为3GB。

## 不使用GOMEMLIMIT
对于第一次运行，我选择了以下设置:
GOMEMLIMIT未设置，
GOGC设置为100。
使用Docker，内存限制设置为3GiB。
目标是导入40万个对象，每个对象附带一个768维的向量。

根据我们的预测，这应该使用略高于2GiB的实时内存。我们会用尽内存吗？

以下是使用上述参数启动Weaviate实例的命令：

```
docker run -it \
  -m 3GiB \
  -e "GOGC=100" \
  -e "PERSISTENCE_DATA_PATH=/var/lib/weaviate" \
  -e "AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true" \
  -e "PROMETHEUS_MONITORING_ENABLED=true" \
  -e "CLUSTER_HOSTNAME=node1" \
  -e "GODEBUG=gctrace=1" \
  -v "$PWD/data:/var/lib/weaviate" \
  -p "8080:8080" \
  -p "2112:2112" \
  weaviate
```

关于上述命令的一些附加说明：
* 我明确将`GOGC`设置为100；如果我没有设置，这也将是默认值。
* 我启用了`GODEBUG=gctrace=1`。这会使垃圾回收器输出更详细的信息。它会在每次运行时记录日志。每条日志消息会打印当前堆大小和新的目标大小。
* 我已启用了使用 `PROMETHEUS_MONITORING_ENABLED=true` 的Prometheus监控，并在端口2112上暴露了指标端口。我还运行了一个Prometheus和Grafana实例。如何设置它们超出了本文的范围，但是在这里有一个很好的端到端[Weaviate Prometheus示例](https://github.com/weaviate/weaviate-examples/tree/main/monitoring-prometheus-grafana)。

现在是时候开始我们的导入并观察结果了。正如预料的那样，我无法导入所有的对象。在大约40万个对象中的约24万个对象之后，可怕的OOM kill发生了：

```
"State": {
            "Status": "exited",
            "Running": false,
            "Paused": false,
            "Restarting": false,
            "OOMKilled": true,  <===============
            "Dead": false,
            "Pid": 0,
            "ExitCode": 137,
            "Error": "",
        },
```

那么，我们从监控中得到的堆图表是什么样的呢？

![在OOM杀死之前](./img/just-before-oom-kill.jpg)

通常在这个时刻，每个人都会说：“我不可能被OOM杀死。看看堆图表，我们从未超过2.5GiB”。他们既对又错。

实际上，长期存在的堆从未超过3GiB的硬限制。但是，通过GC日志，可以看到监控采样率隐藏的内容。以下是在内核发送kill信号之前，日志记录的最后一行内容：

```
gc 178 @351.109s 1%: 0.61+416+0.21 ms clock,
9.8+8.7/1629/695+3.4 ms cpu,
2549->2721->1575 MB, 2729 MB goal,
1 MB stacks, 0 MB globals, 16 P
```

我们如何解释这个输出呢？
* 在最后一次GC周期之后，存活堆（即长期存在的项）约为1575MB。根据我们的100%增长目标，我们现在将超过3GiB的硬限制（2 * 1575 = 3150）。
* GC报告的目标略低于3GiB的硬限制；它报告了2729MB。然而，请记住，在被OOM杀死之前，这是它能够记录的最后一行。如果它没有被杀死，我们可能会看到一个超过3000的值。
* 顺便提一下：一开始的那个1%表示GC花费了大约总CPU时间的1%。这是一个后续比较的良好基准。

### 总结一下，发生了什么？
* 我们的导入失败了；我们只能导入目标负载的约60%。
* 长期存活的内存只占据了约1.5GiB，但是在一台3GiB的机器上收到了OOM信号。
* 解释是使用`GOGC=100`，GC会等待堆的大小翻倍。这实际上意味着在一个3GiB的机器上，我们永远不能安全地使用超过1.5GiB的内存。

## 使用GOMEMLIMIT=2750MiB
现在，我将重复相同的实验。我将保持GOGC为100，但也会引入GOMEM限制。我已将值设置为略低于3000MiB的cgroup限制，即2750MiB。这是因为GOMEM限制只是一个软限制。它不能保证Go运行时永远不会超过它；它只是作为一个新的目标。

使用新的参数，我将像这样调用Weaviate：

```
docker run -it \
  -m 3GiB \
  -e "GOMEMLIMIT=2750MiB" \
  -e "GOGC=100" \
  -e "PERSISTENCE_DATA_PATH=/var/lib/weaviate" \
  -e "AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true" \
  -e "PROMETHEUS_MONITORING_ENABLED=true" \
  -e "CLUSTER_HOSTNAME=node1" \
  -e "GODEBUG=gctrace=1" \
  -v "$PWD/data:/var/lib/weaviate" \
  -p "8080:8080" \
  -p "2112:2112" \
  weaviate
```

现在是时候再次运行相同的实验了...而且，我有一些好消息！导入成功了。让我们运行一个快速的合理性检查来证明确实导入了40万个对象：

```bash
curl localhost:8080/v1/graphql \
  -H 'content-type: application/json' \
  -d '{"query":"{Aggregate{Example{meta{count}}}}"}'

{"data":{"Aggregate":{"Example":[{"meta":{"count":400000}}]}}}
```

正如您所见，导入的内容都已存在，让我们来看一下根据Prometheus指标的堆使用情况：

![GOMEMLIMIT帮助在OOM崩溃前收集垃圾](./img/gomemlimit-in-action.jpg)

图表显示了我们预期的情况：
* 在任何时候，测试都没有超过我们硬性的3GiB限制（因此没有OOM杀死）
* 在接近限制时，堆围绕我们配置的2750MiB GOMEMLIMIT浮动
* 导入完成后，稳定的长期堆减少到略高于2GiB

让我们也来看一下最新的GC日志：

```
gc 313 @692.771s 2%: 0.36+393+0.13 ms clock,
5.7+337/1572/1065+2.1 ms cpu,
2214->2272->2039 MB,
2296 MB goal, 0 MB stacks, 0 MB globals, 16 P
```

再次，这个日志输出证实了我们之前的说法：
* 完成导入后，实时堆的大小略大于2GiB（2039MB）
* 当我们接近软限制时，堆目标不再是实时堆的两倍。相反，它仅略高于实时堆，为2296MB。
* Go运行时在CPU时间上做了有意识的权衡，以避免OOM。我们可以看到GC的自报告开销现在为2%。

### 总结一下，GOMEMLIMIT如何避免OOM？
* 我们能够顺利完成全部导入操作。
* 内存使用量从未超过我们的软限制2.75GiB，因此也从未达到我们的硬限制3GiB。
* 当可用内存较少时，GOMEMLIMIT使得GC更加积极，但在内存充足时保持相对放松。

## 结论：GOMEMLIMIT是一个改变游戏规则的工具！
在本文中，我们涵盖了很多要点，让我总结一下关键要点：
* 内存可以分配在堆栈上（廉价）或堆上（昂贵）。长期存在的内存必须存在于堆上。有时临时内存会“逃逸”到堆上。
* 在 Go 1.19 之前，Go 运行时只能设置相对的垃圾回收目标。这使得有效利用可用内存非常困难。
* 通过我们的实验，我们能够证明，即使应用程序几乎只使用了1500MiB的内存，在一个3GiB的机器上，我们仍然能够让应用程序崩溃。我们只能完成约60%的导入场景。
* 在引入了`GOMEMLIMIT=2750MiB`后，我们的应用程序不再崩溃，并且能够有效地利用可用的内存。导入成功完成。

这是否意味着`GOMEMLIMIT`是你在堆内存分配方面的"出狱卡"？不是的。一个经常使用的Go应用程序仍然需要确保分配效率。简单地设置`GOMEMLIMIT`并不能使一个效率低下的应用程序变得高效。对于一个已经进行了良好优化的应用程序（如Weaviate）来说，`GOMEMLIMIT`可以帮助你充分利用机器资源，防止不必要和令人烦恼的OOM（内存耗尽）问题。

import WhatNext from '/_includes/what-next.mdx'

<WhatNext />