---
authors:
- erika
- jp
date: 2023-04-18
description: Learn about Auto-GPT and how to give it long-term memory with Weaviate!
image: ./img/hero.png
slug: autogpt-and-weaviate
tags:
- integrations
title: Giving Auto-GPT Long-Term Memory with Weaviate
---

![autogpt and weaviate](./img/hero.png)

<!-- truncate -->

:::info Auto-GPT being re-factored
Edit (5/Jun/2023): Auto-GPT has [temporarily removed support for external vector stores as they refactor their code](https://github.com/Significant-Gravitas/Auto-GPT/blob/60ac0c4da15930d5e40af87fba6248ec37a951ee/BULLETIN.md?plain=1#L27).

We are working on re-introducing the integration. For now, please use this version (https://github.com/Significant-Gravitas/Auto-GPT/tree/v0.3.1) to use Auto-GPT with Weaviate.
:::

随着生成式语言模型（如GPT-4）不断推动AI的边界，对其潜力的兴趣迅速蔓延。许多应用和项目都是基于GPT-4构建的，以扩展其能力和功能。此外，许多工具被创建出来，用于与大型语言模型进行交互，例如[LangChain](https://python.langchain.com/en/latest/)。[Auto-GPT](https://github.com/Torantulino/Auto-GPT)是其中最快速崛起的开源Python项目之一，利用了GPT-4的强大力量！

## 什么是Auto-GPT?
Auto-GPT最近受到了很多关注，星星的数量从20k在几天内跳到了80k。Auto-GPT将“思考”链接在一起，自主完成各种任务或作业。它通过使模型能够迭代运行并以隔离的方式完成各种任务，进一步推动了GPT-4的发展。它可以编写代码并执行Python脚本，进行市场调研，甚至订购披萨。

- [编写代码并执行Python脚本](https://twitter.com/SigGravitas/status/1642181498278408193?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1642181498278408193%7Ctwgr%5Eaa2e51a2fc46f95cf982d6baa333a4ea14d1b264%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fcdn.embedly.com%2Fwidgets%2Fmedia.html%3Ftype%3Dtext2Fhtmlkey%3Da19fcc184b9711e1b4764040d3dc5c07schema%3Dtwitterurl%3Dhttps3A%2F%2Ftwitter.com%2FSigGravitas%2Fstatus%2F1642181498278408193image%3Dhttps3A%2F%2Fi.embed.ly%2F1%2Fimage3Furl3Dhttps253A252F252Fabs.twimg.com252Ferrors252Flogo46x38.png26key3Da19fcc184b9711e1b4764040d3dc5c07)
- [进行市场调研](https://twitter.com/BoucherNicolas/status/1646250166834307072)
- [订购披萨](https://twitter.com/Saboo_Shubham_/status/1646739277328314368)

ChatGPT需要人类通过开发和完善文本提示来引导大型语言模型（LLM）。这意味着您需要逐步构建您的请求，以便LLM能够“理解”。另一方面，Auto-GPT能够独立地定义完成分配任务所需的目标，**减少或不需要人类反馈和干预**。这是因为它能够将思维链接在一起的能力。

链式思维是一种帮助语言模型改进推理能力的方法。它将任务分解为完成所需的中间步骤。程序将持续运行，直到完成这些任务。例如，如果它正在处理一个编码项目，它会在进行过程中进行代码调试。

让我们深入了解Auto-GPT在内部是如何工作的。在撰写本文时，Auto-GPT使用GPT-4（或可选的GPT-3.5）进行文本生成，并使用GPT-3.5进行文件存储和摘要。在配置时，Auto-GPT会提供一系列工具，如代码执行器、谷歌搜索API或计算器。此外，还可以通过向量数据库（例如[Weaviate](https://weaviate.io/)）为Auto-GPT提供长期记忆的访问权限。Auto-GPT还可以通过预配置的提示（如摘要）来访问“技能”。

凭借这些工具，Auto-GPT从用户的查询开始。例如，“请列出一张购物清单，并使用每个食材创建一个菜谱。” Auto-GPT接受这个任务，并提出一个行动计划来完成任务，例如：

任务：根据过去的物品列出一张购物清单

计划：
1. 使用来自Weaviate数据库的长期记忆来筛选上周的清单
2. 订购所需的食材
3. 使用互联网查找不同的食谱

行动：
1. 查看以前的购物清单
2. 在线订购杂货
3. 使用互联网收集食谱

由于Auto-GPT能够自主形成这些行动计划，所以确认每个行动是否完成非常重要。如果第一步没有完成，它不应该跳到第二步。它会通过对其行动进行推理来实现这一点。然后它会审查结果并制定一个更精细的计划。能够推理和完善其行动的能力使Auto-GPT变得如此聪明。

## Auto-GPT示例
Twitter上的人们分享了许多使用Auto-GPT构建的演示。可能性是无限的！在本节中，我们将介绍一些热门的例子。

[Sully](https://twitter.com/SullyOmarr/status/1645205292756418562)分享了一个关于使用Auto-GPT进行市场调研的帖子。任务是了解防水鞋的市场，并找到5个竞争对手。然后需要报告每个竞争对手的优缺点。

[Varun Mayya](https://twitter.com/VarunMayya/status/1643902198164717569) 指出了让 Auto-GPT 自主运行的机会。虽然它被指定创建一个应用程序，但它注意到 Node 没有安装，于是它自己找到了一个 Stack Overflow 的链接来下载。

[Shubham Saboo](https://twitter.com/Saboo_Shubham_/status/1646739277328314368) 分享了这个视频，展示了 Auto-GPT 在 Domino's 网站上订购披萨的过程。

![autogpt和weaviate](./img/Weaviate-auto-gpt-dark.png#gh-dark-mode-only)
![autogpt和weaviate](./img/Weaviate-auto-gpt-light.png#gh-light-mode-only)

## 如何在Weaviate中使用它

Auto-GPT具有短期和长期记忆。通过连接到矢量数据库，例如Weaviate，您可以使应用程序能够检索特定的数据。如果您要求Auto-GPT完成其未经训练的任务，这个扩展功能非常有用。例如，如果您拥有关于波士顿客户群的数据，并且希望制作一则广告，Auto-GPT无法完成此任务，因为这些信息不包含在训练数据中。解决这个问题的方法是连接到您的Weaviate实例，以便Auto-GPT可以获取所需的信息。此外，Auto-GPT可以保存和回忆其行动以供将来使用。

这里是[代码库](https://github.com/Significant-Gravitas/Auto-GPT/blob/v0.3.1/autogpt/memory/weaviate.py)，可以查看Weaviate如何在Auto-GPT中集成。

使用Weaviate和Auto-GPT最简单的方式是使用[WCS](https://console.weaviate.cloud)实例。按照[这些步骤](https://weaviate.io/developers/wcs/quickstart#create-a-weaviate-cluster)创建一个沙盒实例，并按照最新的说明从repo安装Auto-GPT，并注意以下内容。
- 在撰写本文时，建议仅使用[最新稳定版本](https://github.com/Significant-Gravitas/Auto-GPT/releases/latest)，而不使用`master`分支。
- 我们建议在Docker容器中运行Auto-GPT，以便在更安全的沙箱环境中运行。
- 如果您打算直接从设备上运行Auto-GPT，而不是在Docker容器中运行，我们建议将所需的库安装到虚拟环境中，而不是安装到系统的Python环境中。

在安装过程中，请根据下面的内容编辑Auto-GPT的`.env`文件中的以下变量：

```
MEMORY_BACKEND=weaviate  # Change from `local`
…

WEAVIATE_HOST=your-endpoint.weaviate.network  # URL to your Weaviate instance (without “https://”)
WEAVIATE_PROTOCOL=https  # http if deploying Weaviate locally with Docker
WEAVIATE_API_KEY=  # Add the API key here if you have authentication enabled
```

然后，您可以启动Auto-GPT。您可以直接在您的设备上运行它，或者在Docker容器内运行。要直接运行它，请运行：
`python -m autogpt`

或者运行以下命令在Docker容器内启动它：

```
docker build -t autogpt .
docker run -it --env-file=./.env -v $PWD/auto_gpt_workspace:/app/auto_gpt_workspace autogpt
```

上述步骤将允许Auto-GPT使用WCS实例作为内存后端，以便根据需要存储和检索信息。

我们注意到使用Docker的本地Weaviate实例会更加复杂。您需要修改`docker-compose`文件，以便Weaviate容器和Auto-GPT容器能够彼此通信。

## 谨慎操作

虽然Auto-GPT是一个很棒的项目，但最好谨慎使用并进行测试。目前它还处于实验阶段，所以最好不要在生产环境中使用。此外，长时间运行Auto-GPT可能会非常昂贵，并且请注意它可能会影响您的设备，例如写入或修改文件以及安装依赖项。如果您的任务需要多个步骤，请注意监控您的OpenAI API使用情况，例如通过设定花费限制。在此处查看免责声明[here](https://github.com/Significant-Gravitas/Auto-GPT#-disclaimer)。


import WhatNext from '/_includes/what-next.mdx'

<WhatNext />