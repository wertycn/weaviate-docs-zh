---
authors:
- jp
date: 2023-01-10
description: Ever wonder how Weaviate turns objects into vectors, behind-the-scenes?
  Find out in this post!
image: ./img/hero.png
slug: pulling-back-the-curtains-on-text2vec
tags:
- integrations
- concepts
title: Pulling back the curtains on text2vec
---

<!-- 截断 -->

![揭开text2vec的面纱](./img/hero.png)

您可能知道Weaviate将文本语料库转换为一组向量 - 每个对象都被赋予一个捕捉其“含义”的向量。但您可能不知道它是如何实现这一点的，或者如何调整这种行为。在这里，我们将揭开面纱，探讨这些问题的答案，揭示一些`text2vec`魔法背后的机制。

首先，我们将仅使用外部API重新生成Weaviate的输出向量。然后我们将看到如何调整文本向量化过程，最后讨论一些相关考虑事项。

## 背景

我经常说Weaviate能够快速而简单地从文本中生成向量数据库。但有时很容易忘记它究竟有多快、多容易。

在过去的五到十年里，即使在“旧时代”，技术上也是可以制作具备向量功能的数据库的。你只需要（深呼吸）开发一个向量化算法，将数据向量化，构建一个向量索引，构建一个包含底层数据的数据库，将向量索引与数据库集成，然后将向量索引查询的结果发送到数据库，并将两者的输出合并（呼气）。

过去的向量搜索绝对不是一个"简单的时代"，鉴于这样的背景，现代向量数据库（如Weaviate）的吸引力非常明显。

但是，尽管未来已经来临，但它还不完美。像Weaviate这样的工具可能看起来就像魔术师的神秘盒子。作为回应，我们的用户会*确切地*询问Weaviate是如何施展魔法的；它是如何将所有的数据转化为向量的，以及如何控制这个过程。

因此，在这篇文章中，让我们一起来探索这个魔法盒子的内部。

如果您想跟着操作，可以在[这里](https://github.com/weaviate/weaviate-examples/tree/main/text2vec-behind-curtain)获取Jupyter笔记本和数据。您可以使用我们免费的[Weaviate云服务](https://console.weaviate.cloud)（WCS）沙盒，或者自己设置Weaviate实例。

> 注意：向量化是由[Weaviate“core”](https://github.com/weaviate/weaviate)完成的，而不是在客户端层面进行的。因此，即使我们使用Python示例，原理是普遍适用的。
让我们开始吧！

## Text2vec：幕后花絮

Weaviate的`text2vec-*`模块将文本数据转换为稠密向量，以便填充Weaviate数据库。每个`text2vec-*`模块使用外部API（如`text2vec-openai`或`text2vec-huggingface`）或本地实例（如`text2vec-transformers`）为每个对象生成一个向量。

让我们尝试使用`text2vec-cohere`模块对数据进行向量化。我们将使用来自`tiny_jeopardy.csv`的数据[在这里可用](https://github.com/weaviate/weaviate-examples/tree/main/text2vec-behind-curtain)，其中包含了来自游戏节目Jeopardy的问题。这里我们只使用了一些（20个）问题，但是[Kaggle上的完整数据集](https://www.kaggle.com/datasets/tunguz/200000-jeopardy-questions)包含了20万多个问题。

将数据加载到Pandas dataframe中，然后像这样填充Weaviate：

```python
for i, row in df.iterrows():
    properties = {
        "question": row.Question,
        "answer": row.Answer
    }
    client.batch.add_data_object(properties, "Question")
client.batch.flush()
```

这应该添加一系列的`Question`对象，具有如下的文本属性：

```text
{'question': 'In 1963, live on "The Art Linkletter Show", this company served its billionth burger',
 'answer': "McDonald's"}
```

由于我们使用`text2vec-cohere`模块对我们的数据进行向量化，因此我们可以查询Weaviate，找到与任何输入文本最相似的数据对象。像这样查找与`快餐连锁店`最接近的条目：

```python
near_text = {"concepts": ["fast food chains"]}
wv_resp = client.query.get(
    "Question",
    ["question", "answer"]
).with_limit(2).with_near_text(
    near_text
).with_additional(['distance', 'vector']).do()
```

这将产生上面的麦当劳`Question`对象，包括对象向量和距离。结果是一个`768`维的向量，与查询向量相距约`0.1`。

这一切都很直观 - 与最大的快餐连锁店（麦当劳）相关的条目从我们的“快餐连锁店”查询中返回。

但是，等等，这个向量是如何得到的呢？

这是“神奇”的部分。让我们看看幕后，看看我们是否能够复制这个“魔术”。具体来说，让我们尝试使用外部API来复制Weaviate为每个对象生成的输出向量。

![拉开窗帘](./img/pulling-back-the-curtains-text2vec.png)

### 匹配Weaviate的向量化

我们知道每个对象的向量对应于其文本。我们不知道的是具体的关联方式。

由于每个对象只包含两个属性，`question`和`answer`，让我们尝试将文本连接起来，并将其与Weaviate进行比较。而且，我们将直接使用Cohere API，而不是`text2vec-cohere`模块。

连接对象中的文本：

```python
str_in = ' '.join([i for i in properties.values()])
```

我们看到：

```text
'In 1963, live on "The Art Linkletter Show", this company served its billionth burger McDonald\'s'
```

然后，使用Cohere API生成向量，如下所示，其中`cohere_key`是API密钥（保持秘密！），`model`是向量化器。

```python
import cohere
co = cohere.Client(cohere_key)
co_resp = co.embed([str_in], model="multilingual-22-12")
```

然后我们运行一个基于`nearVector`的查询，以找到与该向量最匹配的对象：

```python
client.query.get(
    "Question",
    ["question", "answer"]
).with_limit(2).with_near_vector(
    {'vector': co_resp.embeddings[0]}
).with_additional(['distance']).do()
```

有趣的是，我们得到了一个距离为`0.0181`的结果，虽然很小，但不为零。换句话说，我们与Weaviate做了一些不同的事情！

让我们逐一讨论这些不同之处，希望能帮助您了解Weaviate的默认行为。

首先，Weaviate在拼接之前按字母顺序（a-z）对属性进行排序。我们最初的拼接是将`question`文本放在前面，所以让我们将其反转为：

```text
'McDonald\'s In 1963, live on "The Art Linkletter Show", this company served its billionth burger '
```

这将距离降低到`0.0147`。

Weaviate将类名添加到文本中。因此，我们将在单词之前添加`question`，得到：

```text
'question McDonald\'s In 1963, live on "The Art Linkletter Show", this company served its billionth burger'
```

进一步降低距离至 `0.0079`。

然后可以通过将文本转换为小写来消除剩余的距离，如下所示:

```python
str_in = ''
for k in sorted(properties.keys()):
    v = properties[k]
    if type(v) == str:
        str_in += v + ' '
str_in = str_in.lower().strip()  # remove trailing whitespace
str_in = 'question ' + str_in
```

生成中:

```text
'question mcdonald\'s in 1963, live on "the art linkletter show", this company served its billionth burger'
```

再次执行`nearVector`搜索时，结果为零距离（`1.788e-07` - 实际上是零）！

换句话说，我们手动复制了Weaviate的默认向量化过程。它并不是过于复杂，但了解它肯定会有所帮助。让我们回顾一下Weaviate的确切操作。

### Weaviate中的文本向量化

import VectorizationBehavior from '/_includes/vectorization.behavior.mdx';

<VectorizationBehavior/>

既然我们了解了这一点，你可能会问 - 是否可以自定义向量化过程？答案是，当然可以。

## 在Weaviate中调整text2vec向量化

你们中的一些人可能已经注意到，到目前为止我们还没有对模式进行任何操作。这意味着使用的模式是由自动生成模式功能生成的，因此向量化是使用默认选项进行的。

模式是定义数据类型和矢量化器等内容的地方，也可以在类之间设置交叉引用。作为一个推论，可以通过设置相关的模式选项来修改每个类的矢量化过程。实际上，您可以为每个类单独[定义数据模式](/developers/weaviate/configuration/schema-configuration)。

这意味着您可以使用模式来调整Weaviate的向量化行为。与向量化相关的变量是`dataType`以及在类级别和属性级别下`moduleConfig`中列出的变量。

* 在**类**级别上，`vectorizeClassName`将确定是否使用类名进行向量化。
* 在**属性**级别上：
    * `skip`将确定属性是否应在向量化中被跳过（即被忽略），
    * `vectorizePropertyName`将确定是否使用属性名称。
* `dataType`属性确定Weaviate是否忽略该属性，因为它只会忽略除`string`和`text`值之外的所有内容。

> 您可以在[模式配置文档](/developers/weaviate/configuration/schema-configuration)中了解有关每个变量的更多信息。
让我们将此应用于我们的数据，以设置Weaviate的向量化行为，然后我们将使用Cohere API手动确认，就像我们之前所做的那样。

我们的新模式如下所示 - 请注意已注释的行：

```python
question_class = {
    "class": "Question",
    "description": "Details of a Jeopardy! question",
    "moduleConfig": {
        "text2vec-cohere": {  # The vectorizer name - must match the vectorizer used
            "vectorizeClassName": False,  # Ignore class name
        },
    },
    "properties": [
        {
            "name": "answer",
            "description": "What the host prompts the contestants with.",
            "dataType": ["string"],
            "moduleConfig": {
                "text2vec-cohere": {
                    "skip": False,  # Do not skip class
                    "vectorizePropertyName": False  # Ignore property name
                }
            }
        },
        {
            "name": "question",
            "description": "What the contestant is to provide.",
            "dataType": ["string"],
            "moduleConfig": {
                "text2vec-cohere": {
                    "skip": False,  # Do not skip class
                    "vectorizePropertyName": True  # Do not ignore property name
                }
            }
        },
    ]
}
client.schema.create_class(question_class)
```

在模式中定义了一些选项，例如`moduleConfig`/`text2vec-cohere`/`vectorizeClassName`和`properties`/`moduleConfig`/`text2vec-cohere`/`vectorizePropertyName`，它们与其默认值不同。

结果是，使用先前匹配的Cohere API向量进行的`nearVector`搜索现在与距离`0.00395`的向量匹配。

为了将其降至零，我们必须修改文本生成流程以匹配模式。一旦我们完成了这个，它的样子是这样的：

```python
str_in = ''
for k in sorted(input_props.keys()):
    v = input_props[k]
    if type(v) == str:
        if k == 'question':
            str_in += k + ' '
        str_in += v + ' '
str_in = str_in.lower().strip()
```

使用从这个输入生成的向量进行搜索时，与Weaviate中最接近的匹配对象的距离再次为零。我们又回到了原点🙂。

## 讨论和总结

所以，就是这样。在上面的旅程中，我们看到了Weaviate如何从文本数据对象中创建向量，具体包括以下几个步骤：

- 对使用`string`或`text`数据类型的属性进行向量化
- 在连接值之前按字母顺序（a-z）对属性进行排序
- 在属性值之前添加类名
- 并将整个字符串转换为小写
- 我们还看到了如何通过每个类的模式定义来调整此操作。

其中一个影响是，向量化要求是模式定义中非常重要的考虑因素。它可能决定在将相关数据对象导入Weaviate之前如何拆分它们，以及选择导入哪些字段。

让我们再次考虑我们的问答题语料库作为一个具体的例子。假设我们正在构建一个问答应用程序，允许用户搜索问题。那么，最好将每个问答项导入两个类，一个用于问题，一个用于答案，以避免根据用户的查询透露答案。但是我们仍然可以使用答案与用户的输入进行比较。

另一方面，在某些情况下，将多个字段的文本数据导入为一个对象可能更可取。这样，用户可以进行匹配意义的搜索，而无需过多考虑信息所在的确切字段。我们不应忽视其他搜索方法，如BM25F或混合搜索，这些决策都会对其产生影响。

既然你已经看到了幕后发生的事情，我们鼓励你在下次使用Weaviate构建项目时尝试应用这些概念。虽然在我们的示例中相似性的变化可能较小，但在某些领域和语料库中，它们的影响可能会更大。调整准确的向量化方案可能会为你的Weaviate实例提供额外的提升。

import StayConnected from '/_includes/stay-connected.mdx'

<StayConnected />