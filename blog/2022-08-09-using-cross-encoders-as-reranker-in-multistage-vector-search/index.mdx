---
authors:
- laura
date: 2022-08-09
description: Learn about bi-encoder and cross-encoder machine learning models, and
  why combining them could improve the vector search experience.
image: ./img/hero.png
slug: cross-encoders-as-reranker
tags:
- search
title: Using Cross-Encoders as reranker in multistage vector search
---

![在多阶段向量搜索中使用交叉编码器作为重新排序器](./img/hero.png)

<!-- 截断 -->

语义搜索克服了基于关键字的搜索的缺点。如果你搜索"数据科学家的编程"，关键字搜索会找到"数据科学家的编程入门"，但不会返回"机器学习应用中的Python"。

矢量数据库可以利用机器学习来捕捉数据和搜索查询的上下文和语义。通常，机器学习模型在高准确性和速度之间存在权衡。准确性越高，模型的计算成本就越高。如果我们谈论搜索或信息检索，我们希望看到准确的搜索结果，涵盖广泛的查询范围，同时保持高速。

在搜索或句子的语义匹配中，与*Cross-Encoder*模型相比，我们可以看到*Bi-Encoder*模型存在这种权衡。*Bi-Encoder*模型速度**快**，但准确性**较低**，而*Cross-Encoder*模型准确性**更高**，但速度**较慢**。幸运的是，我们可以在搜索流程中将它们结合起来，从两种模型中获益！

在本文中，您将了解这两种机器学习模型，以及为什么将它们结合起来可以提高向量搜索的体验。

## Bi-Encoder模型

像[Weaviate](/developers/weaviate/)这样的向量数据库使用双编码器机器学习模型来计算搜索查询和向量空间中的数据之间的相似性。这些机器学习模型被训练成将数据（如文本、图像、视频、音频等）表示为**向量**，这些向量捕捉了数据的上下文和语义。类似地，搜索查询也可以用向量嵌入表示。然后，向量数据库可以执行相似性搜索以检索与查询嵌入最接近的向量。

计算**数据的稠密向量嵌入**（稍后可用于**搜索查询**）的模型被称为*双编码器模型*。通过计算向量之间的相似度（例如余弦相似度），可以比较数据向量和查询向量。使用双编码器模型可以将数据库中的所有数据项表示为向量嵌入。

> 注意：向量数据库在导入期间计算密集向量嵌入。提前计算向量并与ANN算法（用于更快的检索）结合使用，使得与Bi-Encoder的工作高效。

![向量数据库](./img/vector-database.png)

*图1 - 向量数据库的表示*

![Bi-Encoder](./img/bi-encoder.png)

*图2 - Bi-Encoder模型的表示*

## 交叉编码器模型

Bi-Encoder模型并不是评分相似性的唯一可能方式。另一种策略是使用*Cross-Encoder*。Cross-Encoder模型不会为数据生成向量嵌入，而是使用分类机制来处理数据对。模型的输入始终由一个**数据对**组成，例如两个句子，并输出一个介于0和1之间的值，表示这两个句子之间的相似度（图3）。因此，单独的句子不能传递给Cross-Encoder模型，它总是需要一个**配对**的"项目"。在搜索方面，您需要使用Cross-Encoder分别对每个数据项和搜索查询进行计算，以计算查询和数据对象之间的相似度。

![Cross-Encoder](./img/cross-encoder.png)

*图3 - 交叉编码器模型的表示*


如果在一个代表性的训练集上训练了一个交叉编码器模型，它[比双编码器模型具有更高的准确性](https://arxiv.org/abs/1908.10084)。然而，由于在每个数据项与查询的组合中都需要使用交叉编码器模型进行搜索，这种方法非常低效。对于一个实际的语义搜索应用程序，如果有成千上万甚至上百万的对象，这将是不切实际的，因为执行搜索将需要很长时间。

## 结合双编码器和交叉编码器

我们可以将这两种方法结合起来，从两种模型的优点中受益！我想用一个例子来说明这个想法。想象一下，你是一个在一个充满各种鱼类的海洋中寻找鲑鱼的渔夫。首先，你驶向鱼类丰富的水域，并使用一张带有最佳鲑鱼诱饵的大网捕捉很多鱼。你希望能找到一些鲑鱼，但你的网也会捕捉到其他你不感兴趣的鱼类。接下来，你通过将鲑鱼保留下来，将其他鱼类扔回海中进行分类。这个分类步骤很耗时和昂贵，但非常有效。

![渔夫作为多阶段搜索](./img/fisherman.jpg)

*图 4 - 渔夫作为多阶段搜索*

使用大网捕鱼代表了Bi-Encoder的工作原理。Bi-Encoder速度快，但准确性不如昂贵的渔夫，也就是Cross-Encoder。Cross-Encoder耗时较长，就像渔夫需要限制捕鱼次数一样。因此，我们可以将这两种方法串联在一起（参见图5）。首先，您使用Bi-Encoder检索一个*结果候选列表*，然后您使用Cross-Encoder在这个候选列表上挑选出（或重新排序）最相关的结果。这样，您既可以从Bi-Encoder的高效检索方法中受益，又可以从Cross-Encoder的高准确性中受益，因此可以在大规模数据集上使用它！

![多阶段搜索流程](./img/weaviate-pipeline-long.png)

*图5 - 使用Weaviate的多阶段搜索流程*

## 预训练的Cross-Encoder模型

正如前面提到的，Cross-Encoder可以实现高*领域内*准确性。为了获得最准确的结果，我们使用代表其专业用例的数据集对模型进行训练。

预训练的句子转换器交叉编码器模型可以在[HuggingFace](https://huggingface.co/Cross-Encoder)上获取。在那里，您可以找到许多不同的模型，例如[在MS Marco上训练的模型](https://huggingface.co/cross-encoder/mmarco-mMiniLMv2-L12-H384-v1)，您可以在通用自然语言数据的搜索应用程序中使用该模型（该模型是在Bing搜索查询上训练的）。如果您有一个属于*非领域内*的数据集的搜索任务，您应该训练或微调一个模型，请参考[这里](https://www.sbert.net/examples/training/cross-encoder/README.html)中的示例。

## 结论

我们可以将快速的双编码器和准确的交叉编码器结合在一个搜索流程中，以提高搜索体验。使用像[Weaviate](/)这样的向量数据库，您可以使用双编码器模型对数据和查询进行编码，从而高效地存储和检索向量和数据。然后，搜索流程可以继续使用交叉编码器模型对检索到的搜索结果候选列表进行重新排序。

这篇博客文章的灵感来自[Nils Reimer在Bi-Encoders和Cross-Encoders上的工作](https://www.sbert.net/examples/applications/cross-encoder/README.html)。

import WhatNext from '/_includes/what-next.mdx'

<WhatNext />