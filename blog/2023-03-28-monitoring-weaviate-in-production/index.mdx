---
authors: john
date: 2023-03-28
description: Learn about how to monitor Weaviate in production and observe key metrics.
image: ./img/hero.png
slug: monitoring-weaviate-in-production
tags:
- concepts
- engineering
title: Monitoring Weaviate in Production
---

![在生产环境中监控Weaviate](./img/hero.png)

<!-- 省略 -->

Weaviate被设计为遵循云原生方法来进行监控和观察。为了实现这一点，Weaviate支持以下功能：

1. 将Prometheus指标发布到标准的`/metrics`端点

2. 使用内置的Kubernetes [活跃性和就绪性](/developers/weaviate/api/rest/well-known)检查

3. 通过环境变量配置设置

4. 通过[helm charts](https://github.com/weaviate/weaviate-helm)简化部署

已经有关于[导出指标](/developers/weaviate/configuration/monitoring)的文档，其中还有一个示例，展示如何使用Prometheus实例进行指标监控。

然而，一个常见的问题是：我如何将Weaviate与现有的可观察性堆栈集成？

本文介绍了两种方法，使用Grafana agent或Datadog agent来抓取这些指标。它还提供了一份重要的指标监控清单。

## 先决条件

假设您已经部署了Weaviate。默认情况下，Prometheus监控是禁用的，您可以通过设置环境变量来启用它:

```sh
PROMETHEUS_MONITORING_ENABLED=true
```

Weaviate会在端口`2112`上发布Prometheus指标。

::::note
If you are using Weaviate `1.17` or lower, you may want to upgrade to `1.18` before enabling Prometheus metrics. The reason being Weaviate previously published many histograms which has since been [replaced](https://github.com/weaviate/weaviate/pull/2605) by summaries for performance reasons. Additionally, be careful enabling Prometheus metrics if you have many thousands of classes as you may end up with high cardinality labels due to some metrics being produced per class.
::::

## Grafana Agent
![在生产环境中监控 Weaviate](./img/Weaviate-monitoring-weaviate-in-prod-light.png#gh-light-mode-only)
![在生产环境中监控 Weaviate](./img/Weaviate-monitoring-weaviate-in-prod-dark.png#gh-dark-mode-only)

第一种方法，我们将使用开源的[Grafana agent](https://grafana.com/docs/grafana-cloud/data-configuration/agent/)。在这种情况下，我们将展示如何将指标写入Grafana Cloud。如果您希望将指标写入自托管的Mimir或Prometheus实例，可以通过远程写入部分进行配置。

### 安装步骤

1. 在目标环境中安装Grafana agent，按照[设置指南](https://grafana.com/docs/agent/latest/)进行操作。

2. 配置Grafana的`agent.yaml`文件，包含名为`weaviate`的抓取作业。这将在Kubernetes中自动发现Weaviate的Pod。`app=weaviate`标签是由Weaviate的helm chart自动添加的，这使得自动发现变得简单。

```yaml
metrics:
    configs:
    - name: weaviate
    # reference https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
    scrape_configs:
    - job_name: weaviate
        scrape_interval: 30s
        scheme: http
        metrics_path: /metrics
        kubernetes_sd_configs:
        - role: pod
        selectors:
        - role: "pod"
            label: "app=weaviate"
    remote_write:
    - url: <Your Grafana.com prometheus push url>
        basic_auth:
        username: <Your Grafana.com userid>
        password: <Your Grafana.com API Key>
```

3. 通过在Grafana的"探索"页面中运行以下PromQL查询，验证是否收到数据。

```
go_memstats_heap_inuse_bytes{job="weaviate"}
```
### 仪表盘

使用这种方法的一个好处是，您现在可以重用现有的Weaviate Grafana仪表盘。

导入这些仪表盘的步骤：

1. 下载并导入[预设的仪表盘](https://github.com/weaviate/weaviate/tree/master/tools/dev/grafana/dashboards)。

2. 如果您正在使用Grafana Cloud托管的Prometheus，您需要对仪表盘进行修补，将数据源uid更改为`grafanacloud-prom`，如下所示。

```sh
sed 's/"uid": "Prometheus"/"uid": "grafanacloud-prom"/g' querying.json > querying-patched.json
```

仪表板现在应该可见了！

![查询延迟](./img/query-latency.png)

## Datadog

[Datadog](https://www.datadoghq.com/) 是另一个流行的可观测性解决方案，Datadog代理支持抓取Prometheus指标。

### 安装步骤

1. 安装Datadog代理。在本示例中，使用了它们的[Helm](https://docs.datadoghq.com/containers/kubernetes/installation/?tab=helm)图表进行安装。

2. 提供一个包含以下内容的 `datadog-values.yml` 配置。您还可以使用该方法捕获 Weaviate 日志。

```yaml
datadog:
# Note DD_KUBELET_TLS_VERIFY only needs to be set if running a local docker kubernetes cluster
#  env:
#  - name: DD_KUBELET_TLS_VERIFY
#    value: "false"
  clusterName: weaviate-deployment
  prometheusScrape:
    enabled: true
    serviceEndpoints: true
    additionalConfigs:
      - configurations:
        - max_returned_metrics: 20000
          min_collection_interval: 30
```

3. 自定义Weaviate [helm chart](https://github.com/weaviate/weaviate-helm/blob/80346f0f1e1f22ad84a899b5f9e12f44be3ee809/weaviate/values.yaml#L730)，添加注释 `prometheus.io/scrape` 和 `prometheus.io/port`。

```yaml
# Pass any annotations to Weaviate pods
annotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "2112"
```

4. 验证指标是否可用。即使是空架构，`go_memstats_heap_inuse_bytes` 应该始终存在。

![datadog 概要](./img/datadog-summary.png)

## 关键指标

以下是一些要监控的关键 Weaviate 指标。标准的 CPU、磁盘、网络指标也很有用，还有 [Kubernetes 事件](https://grafana.com/blog/2023/01/23/how-to-use-kubernetes-events-for-effective-alerting-and-monitoring/)。
请注意，只有发生了操作（例如批量操作），才会显示一些Weaviate指标。

### 堆使用情况

对于堆使用情况，预期是在负载下，内存会呈现出标准的起伏模式，但由于Go语言的垃圾回收机制，内存会定期降低。如果内存没有下降，而是保持非常接近[GOMEMLIMIT](/blog/gomemlimit-a-game-changer-for-high-memory-applications)，则可能需要增加资源。

```
go_memstats_heap_inuse_bytes
```

### 批处理延迟

批处理延迟很重要，因为批处理操作是将数据写入Weaviate的最有效方式。监控这个指标可以提醒是否存在索引数据的问题。该指标具有一个名为`operation`的标签，用于标识操作类型。
允许您查看对象、向量和倒排索引子操作所需的时间。如果您使用[向量化模块](/developers/weaviate/modules/retriever-vectorizer-modules)，由于发送数据到模块的开销，您将看到额外的延迟。

```
rate(batch_durations_ms_sum[30s])/rate(batch_durations_ms_count[30s])
```

对于批量删除操作，对应的`batch_delete_durations_ms`指标也会很有用。

### 对象延迟

通常情况下，建议使用批量索引操作，但也有一些情况下你可能需要进行单个的`PUT`或`DELETE`操作，比如处理用户在应用程序中的实时更改。在这种情况下，你需要监控对象的延迟。

```
rate(objects_durations_ms_sum{operation="put"}[30s])/rate(objects_durations_ms_latency{operation="put"}[30s])
```

### 查询延迟和速率

查询延迟和每秒查询数也非常重要，特别是用于监控使用模式。

```
rate(queries_durations_ms_sum[30s])/rate(queries_durations_ms_count[30s])
rate(queries_durations_ms_count)[30s]
```

## 其他集成

还有许多其他解决方案可以与Prometheus集成使用：

* [Elastic](https://docs.elastic.co/integrations/prometheus)
* [Splunk](https://www.splunk.com/en_us/blog/devops/metrics-from-prometheus-exporters-are-now-available-with-the-sfx-smart-agent.html)
* [New Relic](https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/)

import StayConnected from '/_includes/stay-connected.mdx'

<StayConnected />