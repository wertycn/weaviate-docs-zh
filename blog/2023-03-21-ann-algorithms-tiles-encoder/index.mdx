---
authors:
- abdel
date: 2023-03-21
description: Using the Weaviate Tile Encoder to compress vectors with Product Quantization.
image: ./img/hero.png
slug: ann-algorithms-tiles-enocoder
tags:
- research
title: The Tile Encoder - Exploring ANN algorithms Part 2.2
---

![The Tiles Encoder - 探索ANN算法 第2.2部分](./img/hero.png)

<!-- truncate -->

在我们之前的帖子中，我们解释了如何在内存中压缩向量。这是一个重要的第一步，因为我们仍然可以通过一个非常低的内存占用来引导我们对查询进行搜索的粗略表示。我们介绍了HNSW+PQ，并解释了最流行的编码技术：KMeans，它可以用于找到向量的压缩表示。虽然KMeans可以得到非常好的结果，但也有一些缺点。首先，拟合数据的成本很高。其次，在压缩向量时，它需要计算每个片段到所有质心的距离。这导致了较长的编码和索引时间。

在这篇博客文章中，我们介绍了一种替代KMeans的方法，即Tile编码器，它是一种基于分布的编码器。Tile编码器的工作原理与KMeans非常相似，但它不需要根据数据进行拟合，因为它利用了我们事先知道数据的底层分布的事实。

## Tile编码器
![tiles](./img/Ann.png)

KMeans使用质心在整个值范围上生成平铺。每个质心都与一个平铺相关联。当需要对新向量进行编码时，算法会检查它属于哪个平铺，并使用最接近的平铺的索引来设置向量编码。当将KMeans拟合到我们的数据时，平铺的生成是不均匀的。因此，我们预计在数据密度较高的地方会有更多的平铺。这样，数据将在质心上平衡分布。

让我们花点时间来探索KMeans拟合到我们数据中的质心是如何分布的。如果我们在Sift1M上每个维度使用一个段，质心的分布如图1所示。

![image1](./img/image1.png)

**图1**: *在Sift1M上第一维度的质心分布。请注意质心的分布呈以零为中心的对数正态分布。*

聚类中心明显遵循对数正态分布。这是维度值遵循相同分布的结果。Sift1M和Gist1M中的所有维度都分布为对数正态分布。而DeepImage96中的所有维度则遵循正态分布。数据的分布将受到用于生成向量的矢量化方法的影响。

如果我们提前知道数据的分布，我们可能可以在不使用KMeans拟合数据的情况下生成聚类中心。我们只需要根据数据的分布在整个值范围上生成一个网格即可。

假设我们想为每个维度生成一个字节码。这类似于使用KMeans，每个维度对应一个段落。但我们不使用KMeans，而是使用数据分布的[累积密度函数](https://en.wikipedia.org/wiki/Cumulative_distribution_function)（CDF）来生成代码。CDF会生成从零到一的值。我们希望有256个代码，但通常我们可能希望使用任意数量的代码（因此可以使用更多或更少的位来进行编码）。代码可以计算为$code(x)=CDF(x)*c$，其中$c$是要使用的代码数量。

另一方面，当我们需要对数据进行解压缩时，我们需要从编码中生成质心。为此，我们需要使用CDF函数的反函数，也就是需要使用[分位数函数](https://en.wikipedia.org/wiki/Quantile)。
这种方法的真正优势在于，我们不再需要花费很长时间来拟合数据。我们可以在数据添加时逐步计算均值和标准差（作为分布的参数），然后就完成了。

这也为随着时间推移轻松更新产品量化数据提供了良好的机会，因为整个过程在时间上非常廉价。如果我们的数据开始漂移，那么这种情况将非常有趣。如果我们压缩数据，然后由于一些新的趋势，数据开始漂移，那么数据的分布将会发生变化，压缩数据（从KMeans质心生成的编码）将会过时。使用Tile编码器，我们可以监控这种情况并快速更新数据。


## 质心分布

为了更好地理解质心的分布情况，让我们创建一些使用生成的质心的插图。

![image2](./img/image2.png)
![image3](./img/image3.png)

**图2**：*由KMeans和Tile编码器生成的质心。两个图表都显示了前两个片段的笛卡尔积。两个编码器都使用了32个质心进行拟合。上面显示的是来自KMeans的质心，下面显示的是来自Tile的质心。*

正如我们可以观察到的那样，这两种方法生成的结果相似。质心在两个轴的原点处非常密集，随着数值的增长，质心变得更加稀疏。值得一提的是，多变量方法比单独构建段落的笛卡尔积更适合拟合数据。为了说明这一点，我们展示了图3。

![image4](./img/image4.png)
![image5](./img/image5.png)

**图3**：*KMeans在包括前两个维度的第一个片段上生成的质心。编码器使用32个（上方）和256个（下方）质心进行拟合。使用足够数量的质心时，质心更好地适应数据的分布，而不是为每个维度使用独立的片段。*

我们尚未将平铺编码器扩展到多变量情况。虽然这并不是非常困难，但仍需要一些工作，并将在不久的将来包含在内。我们决定发布这个初始实现，以便可以用更多的数据进行测试。

请注意，这个编码器依赖于数据分布事先已知的事实。这意味着您需要提前提供这些信息。目前我们支持正态分布和对数正态分布，它们非常常见。如果您的数据遵循不同的分布，扩展代码非常简单，所以请随时与我们联系。

## KMeans与Tile编码的结果

在本节中，我们将介绍使用KMeans与Tile编码器进行产品量化的比较结果。

表格1显示了使用KMeans和Tile编码器进行产品量化的比较。我们比较了计算距离的时间、拟合和编码数据的时间以及召回率。由于目前Tile编码器只支持每个段落一维的设置，因此我们只与KMeans的这个设置进行比较。此外，拟合和编码时间是在10个核心同时运行的，而距离计算是基于单核度量的。

|        | 数据库      | 数据大小 | 适应性   | 编码     | 计算距离时间（$ms$）                     | 召回率   |
|--------|-------------|-----------|---------|---------|----------------------------------------|---------|
| KMeans | Sift        | 1 M       | 3m15s   | 1m30s   | 701                                    | 0.9973  |
|        | Gist        | 1 M       | 22m52s  | 10m10s  | 5426                                   | 0.95    |
|        | DeepImage96 | 1 M       | 2m14s  | 10m17s | 5276                                   | 0.9725 |
| Tile   | Sift        | 1 M       | 294ms  | 2s     | 737                                    | 0.9702 |
|        | Gist        | 1 M       | 4s     | 16s    | 5574                                   | 0.962  |
|        | DeepImage96 | 9.99 M    | 122ms  | 8s     | 5143                                   | 0.9676 |

**表格 1**：*使用KMeans和Tile编码器进行产品量化的结果。*

上述的召回结果是积极的。与KMeans编码器相比，在Sift和DeepImage数据集中，我们使用Tile的召回率较低。在Gist数据集中，与KMeans编码器相比，我们实际上有更好的召回结果。目前撰写本文时，尚未确定造成这种差异的原因。一个显著的差异是向量大小。可能是因为在较大的向量上，单个维度上的离散点的独立误差不那么显著，因为它们会被其他维度吸收。这只是一种假设。

在性能方面，结果非常积极。首先要注意的是，拟合和编码同时在十个核心上运行。这意味着如果你单线程运行，对于在Gist上拟合200,000个向量并对整个数据进行编码，需要花费将近5个小时。相比之下，使用Tile编码器只需要将近三分钟。

此外，请注意当使用产品量化与HNSW时，我们需要在某个时刻进行压缩。这意味着需要适应现有数据并对现有向量进行编码。同时，还需要在新向量到来时对其余的向量进行压缩。当使用KMeans时，我们需要等待一段时间进行数据压缩。在此期间，服务器将无法提供查询服务，因为数据还没有准备好使用。而使用Tile编码器，则压缩操作几乎立即返回可用状态。

此外，我们需要一些数据来触发压缩操作，因为我们需要编码器学习数据的分布情况。过早地进行压缩可能会影响编码的精度。此外，请注意索引过程依赖于搜索过程。查询时间的长短取决于数据的分割情况，可能会缩短或延长。如果您希望保持召回率，则很可能不会使用粗略的分割，这意味着查询时间会增加而不是缩短。较长的查询时间会导致较长的索引时间。在这种情况下，我们越早进行压缩，索引时间就会越长，因为更多的数据将在压缩设置下进行索引。越晚进行压缩，KMeans拟合的时间也会更长，因为它需要拟合更多的数据。另一方面，使用Tile进行拟合几乎是立即完成的，因此越晚进行压缩，索引速度就会更快。实际上，如果您有足够的内存来对未压缩的数据进行索引，但只需要在索引完成后压缩数据（由于某些操作限制），那么我们建议您按照正常流程进行索引，然后使用Tile编码器压缩数据，这样索引时间与常规HNSW相比将保持不变。但是，如果使用KMeans，则无法将索引时间保持与常规HNSW一样短。

## 性能结果

在下图中，我们展示了HNSW+PQ在本文所涉及的三个数据库上的性能。所有实验都是先使用未压缩的方式添加了20万个向量，然后进行压缩并添加其余的数据。正如之前提到的，如果您先添加所有数据，然后再使用Tile编码器进行压缩，您将得到与使用常规HNSW相同的索引时间。这样做的话，最终您在查询服务器时将需要更少的内存，但在索引时实际上需要更多的内存，因为在某个时刻您会同时拥有所有未压缩和压缩的向量，但在索引完成后会立即释放未压缩的向量。

![image6](./img/image6.png)
**图4**：*图表显示了召回率（纵轴）与延迟（微秒为单位，横轴）之间的关系。对于这个实验，我们使用了普通的HNSW算法添加了20万个向量，然后切换到压缩算法，并添加了剩下的80万个向量。*

![image7](./img/image7.png)
**图 5**：*图表显示了召回率（垂直轴）与索引时间（以分钟为单位，水平轴）的关系。在这个实验中，我们使用普通的HNSW算法添加了20万个向量，然后切换到压缩模式并添加了剩余的80万个向量。*

![image8](./img/image8.png)
**图6**：*该图显示了召回率（纵轴）与延迟（微秒为单位，横轴）之间的关系。在这个实验中，我们使用了普通的HNSW算法添加了1,000,000个向量，然后切换到压缩算法，并添加了剩余的8,990,000个向量。*

![image9](./img/image9.png)
**图7**：*该图显示了召回率（纵轴）与索引时间（以分钟为单位，横轴）之间的关系。对于这个实验，我们使用了普通的HNSW算法添加了100万个向量，然后切换到压缩模式，并添加了剩下的8,990,000个向量。*

![image10](./img/image10.png)
**图8**：*图表显示了召回率（纵轴）与延迟（以微秒为单位，横轴）之间的关系。对于这个实验，我们首先使用普通的HNSW算法添加了20万个向量，然后切换到压缩算法并添加了其余的80万个向量。*

![image11](./img/image11.png)
**图9**：*图表显示了召回率（垂直轴）与索引时间（水平轴，以分钟为单位）的关系。在这个实验中，我们使用了普通的HNSW算法添加了20万个向量，然后切换到压缩算法并添加了剩余的80万个向量。*

## 结论

在本文中，我们介绍了Tile编码器，这是我们在上一篇文章中提到的KMeans编码器的一个替代方案。以下是一些关键要点：
- 使用KMeans和Tile编码器时，召回结果非常相似。
- 使用Tile编码器时，需要提供数据的分布情况。
- 使用Tile进行拟合是立即完成的，而使用KMeans则需要更长时间。
- 使用Tile编码器进行压缩时，不会出现停机时间，而使用KMeans编码器进行压缩时，服务器将无法进行查询。
- 如果在索引数据时有足够的内存，使用Tile编码器时可以获得相同的索引时间。

import WhatNext from '/_includes/what-next.mdx'

<WhatNext />